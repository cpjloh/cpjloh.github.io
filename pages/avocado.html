<!DOCTYPE html>
<html>
    <head>
        <title>Jacob Loh</title>
        <link rel="stylesheet" href="../styles/styles.css">
        <script src="../scripts/script.js"></script>
        <meta charset="UTF-8">
        <meta name="author" content="Jacob Loh">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <html lang ="en-US">
    </head>
    <body>
        <header>
            <a href="../index.html">
            <h1>Jacob Loh</h1>
            </a>
        </header>
        <hr>
        <nav style="margin-top:3%;margin-bottom:3%;">
            <ul style="text-align:center;">
                <li id="nav_li"><a href="../index.html#about">About</a></li>
                <li id="nav_li"><a href="../index.html#experience">Experience</a></li>
                <li id="nav_li"><a href="../index.html#projects">Projects</a></li>
                <li id="nav_li"><a href="../index.html#education">Education</a></li>
                <li id="nav_li"><a href="../index.html#contact">Contact</a></li>
            </ul>
        </nav>
        <hr>
        <div id="avocado">
            <a href="../index.html#projects"><h3>Automatic Object Avoidance in Collaborative Vehicles (Senior Project)</h3></a>
            <h4 style="margin-top:0">October 2018 - June 2019</h4>
            <u><b><a href="#avocadoTimeline">SEE VIDEOS BELOW!!!</a></b></u>
            <p>A brief background on this project.
            </p>
            <p>The project's goal was to demonstrate the feasibility and value
            of developing vehicle-to-vehicle communication to enable vehicle
            platooning. There are many benefits that result from platooning
            (reduced fuel consumption and traffic congestion for starters), but
            safe platooning poses significant challenges.
            </p>
            <p>For this project, we developed two small-scale vehicles and made
            them fully autonomous. After doing so, we tied the vehicles together
            over WiFi to allow them to communicate and act simultaneously.
            </p>
            <p>This project taught me a great deal in both technical and
            soft skills. The technical skills I learned included software
            design, computer vision, machine learning, hardware interfacing, 
            design for failure, and more. I wrote thousands of lines of code
            consistenting primarily of Python, C, and bash, while managing
            the codebase using our team's GitHub. The soft skills included 
            writing technical papers, public speaking (I gave a ton of talks, 
            including to Cal Poly's Industrial Advisory Board and at the 
            Enhanced Safety of Vehicles conference in the Netherlands), 
            teamwork, and leadership.
            </p>
            <p>This project was truly a phenomenal experience that transformed
            who I am as a professional and as an academic, and I know it would
            not have been possible without the support of my teammates,
            professors, industry sponsors, and last but not least, my dad.
            </p>
            <p>We won 2nd place at the international student design
            competition at the Enhanced Safety of Vehicles conference in the
            Netherlands. Our paper and a picture of some of our team members
            can be viewed <u><b><a href="https://www-esv.nhtsa.dot.gov/SSTDC.html?view=10">
                        here</a></b></u>.
            </p>
            <u><b><a href="#avocadoTimeline">SEE VIDEOS BELOW!!!</a></b></u>
            <!--
            <p>My computer engineering capstone project
            aims to implement <strong>lane keeping</strong>, <strong>object
                detection and classification</strong>, and <strong>
                vehicle-to-vehicle communication</strong> to allow a platoon
            of vehicles to collaboratively respond to a dynamic situations.</p>
            <p>My primary contributions are:</p>
            <ul>
                <li>Lane tracking using computer vision</li>
                <li>Designing and building system framework</li>
                <li>Project management</li>
            </ul>
            <p>My technical work has been <strong>utilizing
                OpenCV</strong> with <strong>Python</strong> for lane tracking.
            I have also been <strong>writing and managing system 
            processes</strong> using <strong>C++</strong>.
            Some videos of my work are below.</p>
            <p>Note: I have <em>really</em> enjoyed this project, as well as my
            computer vision course, and will ideally find work in this
            field.</p>
            <p>The above is outdated. I'll update it when I have time. Sorry!
            </p>
            -->
            <div id="avocadoTimeline">
            <hr>
            <h4>Fall 2018</h4>
            <p>The following video shows my lane detection algorithm on a section of southbound
            Highway 101, north of Paso Robles. The algorithm identifies the lane lines within a
            region of interest and paints them green for programmer visibility.
            The center point tracks the center of the lane, which is used as
            input to our PID lane keeping controller.
            </p>
            <video
                 alt="Lane Tracking on 101 South Video"
                title="Lane Tracking on 101 South Video" controls>
                <source src="../media/laneTrackingWebsite.mp4" type="video/mp4">
            </video>

            <hr>
            <h4>February 16, 2019</h4>
            <p>After many
            hours of my teammate and me working on electronics and
            software we were able to produce the following. 
            The video shows lane lines mounted on a chair (seen
            at the bottom of the frame) and a camera (on the desk). The camera
            captures video, which it feeds to the not-so-micro Jetson TX2 
            microcontroller for the necessary image processing. Finally, a 
            pwm signal is sent to an Arduino (we do this because the Arduino, 
            unlike the Jetson, has pwm hardware), which then controls 
            the vehicle.
            </p>
            <video
                 alt="Lane Tracking in lab"
                title="Lane Tracking in lab" controls>
                <source src="../media/firstLaneTrackingOnCar.mp4" type="video/mp4">
            </video>
            <hr>
            <h4>February 17, 2019</h4>
            <p>This video shows our car driving
            on the track and navigating an S-bend! I was able to 
            access the car through WiFi
            (ssh) and run a script to start the vehicle. The vehicle
            navigates the roadway and I manually shut off the vehicle
            when it reaches the end of the roadway. A teammate is holding
            string tied to the car should the system fail and the car try to
            drive away (we have not yet set up the system to shut off on a
            disconnect from my laptop).
            </p>
            <p>Note that the hardware is a mess right now as it allows for easy
            access of electronics in the development phase. We'll clean it up
            over time.
            </p>
            <video
                 alt="Lane Tracking on track for first time"
                title="Lane Tracking on track for first time" controls>
                <source src="../media/firstSBend.mp4" type="video/mp4">
            </video>
            <hr>
            <h4>February 25, 2019</h4>
            <p>This video shows our car driving
            around the track for one of the first times! The main differences
            between the car in the previous video and now are:
            </p>
            <ul>
                <li>Video logging to assist with debugging.</li>
                <li>Improved lane tracking.</li>
                <li>A new electronic speed controller (ESC) to allow for
                    more consistent motor control.</li>
                <li>Improved gains in the lane tracking PID controller.</li>
                <li>Better track design.</li>
                <li>Confidence!</li>
            </ul>
            <p>This project is incredibly fun, but incredibly time consuming.
            Still, we make progress most days, and that alone is motivation
            to keep working on it...the best is yet to come!
            </p>
            <video
                 alt="Lane Tracking around track for first time"
                title="Lane Tracking around track for first time" controls>
                <source src="../media/aroundTrack.mp4" type="video/mp4">
            </video>
            <p></p>
            <video
                 alt="Lane Tracking around track for first time from the car's perspective"
                title="Lane Tracking around track for first time from the car's perspective" controls>
                <source src="../media/avocado/firstTimeAroundTrack.mp4" type="video/mp4">
            </video>

            <hr>
            <h4>Meanwhile...</h4>
            <p>I'll add more here when I get the chance (I know it's a MASSIVE
            jump from February 25 to May 29). I did take the time to add a few
            videos though of what is essentially the final product!
            </p>
            <p>Somewhere in here (specifically an 80-hour week over spring break),
            we managed to get the lane keeping fast (as in the car's can drive 
            the track quickly) and reliable, we developed communication
            between the vehicles, we developed controllers to modulate the
            speeds between the vehicles (even though they are built identically,
            they have slight mechanical differences that must be resolved with
            PID controllers), and lane changing capabilities (which will be
            utilized by the object detection).
            </p>

            <hr>
            <h4>May 29, 2019</h4>
            <p>The following video shows the lead vehicle dodging staggered
            pedestrians using a YOLO neural network for pedestrian detection.
            All commands (speed, braking, and lane changes) are communicated to
            the following vehicle immediately over WiFi.
            </p>
            <video
                 alt="Dodging staggered pedestrians from the lead vehicle's POV"
                title="Dodging staggered pedestrians from the lead vehicle's POV" controls>
                <source src="../media/avocado/excellentSalsaDodging.mp4" type="video/mp4">
            </video>
            <p>This video shows the following vehicle dodging staggered
            pedestrians. Unlike the lead vehicle, the following vehicle has no
            ability to detect objects (this was deliberate) as it demonstrates
            the power of vehicle-to-vehicle communication. A hardcoded delay
            allows the following vehicle to change lanes in the same place as
            the lead vehicle, allowing for the following vehicle to dodge
            between objects.
            </p>
            <video
                 alt="Dodging staggered pedestrians from the following vehicle's POV"
                title="Dodging staggered pedestrians from the following vehicle's POV" controls>
                <source src="../media/avocado/excellentChipsDodging.mp4" type="video/mp4">
            </video>
            <p>And the same video from an observer's perspective...
            </p>
            <video
                 alt="Dodging staggered pedestrians from an observer's POV"
                title="Dodging staggered pedestrians from an observer's POV" controls muted>
                <source src="../media/avocado/excellentDodgingOutsidePOV.mp4" type="video/mp4">
            </video>

            <hr>
            <h4>June 12, 2019</h4>
            <p>At competition, the YOLO neural network failed as the dim, orange
            lighting in the conference center produced images that were
            sufficiently different from the training data that the neural
            network could no longer identify obstacles. Thus, over the course of
            a day, another teammate and I rewrote the entire object detection
            algorithm to be based entirely on the depth map collected from the
            stereoscopic cameras. The lane lines were passed to the object
            detection algorithm, which then estimated where the road was to
            determine if any obstacles identified in the depth map threatened
            the vehicle's safety. If so, it would check the other lane. If both
            lanes were blocked, the vehicle would stop. If only its own lane
            was blocked, the vehicle would change lanes.
            </p>
            <p>Note that the red boxes are the regions to be searched for
            obstacles and the green lines are projections of the lane lines. In
            this video you can see the vehicle dodge my teammate's leg and stop
            when he stands in both lanes.
            </p>
            <video
                 alt="Object detection using a depth map"
                title="Object detection using a depth map" controls>
                <source src="../media/avocado/outputDN.mp4" type="video/mp4">
            </video>
            <p></p>
            <video
                 alt="Object detection using a depth map"
                title="Object detection using a depth map" controls>
                <source src="../media/avocado/ESVdodging.mp4" type="video/mp4">
            </video>

            <hr>
            <h4>June 12, 2019</h4>
            <p>Collecting our 2nd place award at the Enhanced Safety of Vehicles
            international student design competition! From left to right: Art
            Carter (US Department of Transporation), Professor Charles Birdsong,
            Cole Oppenheim, Nick Lampe, Jacob Loh, and Kiyoshi Moran.
            </p>
            <p>Not pictured: Professor Bruce DeBruhl, Kyle Bybee, James Gildart,
            and Toan Le.
            <img src="../media/esv.jpg" alt="Receiving 2nd place award"
                title="Enhanced Safety of Vehicles Awards Ceremony" 
                style="width:60%; height:60%">

            <br>
            </div> <!-- end of avocado timeline -->
        </div>
        <footer>
            <p>Last updated: July 22, 2019</p>
        </footer>
    </body>
</html>

